# ir_ranking-machine_learning

Problem: Represent documents as numerical features, and apply machine learning to obtain retrieval ranked lists.

Restrict the data to documents present in the QREL. That is, for each of the 25 queries only consider documents that have a qrel assessment. You should have about 14193 documents; some of the docIDs will appear multiple times for multiple queries, while most documents will not appear at all. For each query, consider additional non-relevant documents (not from qrel) so that you end up with about 1000 non-relevant docs per query. Get these from ranked lists generated by running IR models on the parsed AP89 corpus.

Data:
1. Ranked result lists for the following models using unmodified queries (./Data/query_desc.51-100.short.txt):
    1. Okapi BM25
    2. Unigram language model with Jelinek-Mercer smoothing
    3. Unigram language model with Laplace smoothing
    4. Okapi tf-idf
    5. Okapi tf
2. qrels file qrels.adhoc.51-100.AP89.txt determines whether a document from the ranked list is relevant (1) or not (0) for a particular query
3. qtf2 gives us the number of query terms in the doc (i.e. overall query term frequency), query term percentage, and doc len of each doc for a particular query (note: doc lens for a doc are the same across different queries obviously). File format is *queryID docID queryTermFreq queryTermPercentage docLen* where queryTermPercentage = queryTermFreq / docLen

data.pkl contains the pandas dataframe used to train and test models in model.ipynb